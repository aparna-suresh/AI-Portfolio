<html>
<head>
<title>3_fsa_peft.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #8c8c8c; font-style: italic;}
.s1 { color: #080808;}
.s2 { color: #0033b3;}
.s3 { color: #067d17;}
.s4 { color: #0037a6;}
.s5 { color: #1750eb;}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
3_fsa_peft.ipynb</font>
</center></td></tr></table>
<pre><span class="s0">#%% 
</span>
<span class="s2">import </span><span class="s1">torch</span>
<span class="s2">from </span><span class="s1">transformers </span><span class="s2">import </span><span class="s1">AutoTokenizer, AutoModelForSequenceClassification</span>
<span class="s2">import </span><span class="s1">mlflow</span>
<span class="s2">from </span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">load_dataset, DatasetDict, ClassLabel</span>
<span class="s2">from </span><span class="s1">hyperopt </span><span class="s2">import </span><span class="s1">hp, Trials, fmin, tpe, STATUS_OK</span>
<span class="s2">from </span><span class="s1">transformers </span><span class="s2">import </span><span class="s1">TrainingArguments, Trainer, EarlyStoppingCallback</span>
<span class="s2">from </span><span class="s1">sklearn.metrics </span><span class="s2">import </span><span class="s1">log_loss, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix,ConfusionMatrixDisplay</span>
<span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>

<span class="s2">import </span><span class="s1">warnings</span>
<span class="s1">warnings.filterwarnings(</span><span class="s3">&quot;ignore&quot;</span><span class="s1">, category=FutureWarning)</span>
<span class="s2">import </span><span class="s1">logging</span>
<span class="s1">logging.getLogger(</span><span class="s3">&quot;mlflow&quot;</span><span class="s1">).setLevel(logging.ERROR)</span>

<span class="s0">#%% 
</span><span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s1">val_df = pd.read_csv(</span><span class="s3">'../twitter_fsa/data/validation_cleaned.csv'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">get_sample_weight_dict(df):</span>
    <span class="s1">rating_counts = df[</span><span class="s3">'label'</span><span class="s1">].value_counts()</span>
    <span class="s1">print(</span><span class="s3">f&quot;rating value counts === </span><span class="s4">{</span><span class="s1">rating_counts</span><span class="s4">}</span><span class="s3">&quot;</span><span class="s1">)</span>
    <span class="s1">max_rating_count = rating_counts.max()</span>
    <span class="s1">print(</span><span class="s3">f&quot;max rating count === </span><span class="s4">{</span><span class="s1">max_rating_count</span><span class="s4">}</span><span class="s3">&quot;</span><span class="s1">)</span>
    <span class="s1">weight_dict = (max_rating_count / rating_counts).to_dict()</span>
    <span class="s1">print(</span><span class="s3">f&quot;weight_dict === </span><span class="s4">{</span><span class="s1">weight_dict</span><span class="s4">}</span><span class="s3">&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">weight_dict</span>

<span class="s1">sample_weight_dict = get_sample_weight_dict(val_df)</span>
<span class="s1">val_sample_weights = val_df[</span><span class="s3">'label'</span><span class="s1">].map(sample_weight_dict)</span>
<span class="s0">#%% 
</span><span class="s1">chkpt = </span><span class="s3">&quot;distilbert/distilbert-base-uncased&quot;</span>
<span class="s1">tokenizer = AutoTokenizer.from_pretrained(chkpt)</span>
<span class="s1">device = </span><span class="s3">&quot;cuda&quot; </span><span class="s2">if </span><span class="s1">torch.cuda.is_available() </span><span class="s2">else </span><span class="s3">&quot;cpu&quot;</span>
<span class="s1">print(</span><span class="s3">f&quot;device : </span><span class="s4">{</span><span class="s1">device</span><span class="s4">}</span><span class="s3">&quot;</span><span class="s1">)</span>

<span class="s0">#%% 
</span><span class="s1">experiment_name = </span><span class="s3">&quot;Financial Sentiment Analysis&quot;</span>
<span class="s1">mlflow.set_experiment(experiment_name)</span>
<span class="s0">#%% 
</span><span class="s1">train_dataset = load_dataset(</span><span class="s3">&quot;csv&quot;</span><span class="s1">,data_files=</span><span class="s3">&quot;data/train_cleaned.csv&quot;</span><span class="s1">)[</span><span class="s3">&quot;train&quot;</span><span class="s1">]</span>
<span class="s1">val_dataset = load_dataset(</span><span class="s3">&quot;csv&quot;</span><span class="s1">,data_files=</span><span class="s3">&quot;data/validation_cleaned.csv&quot;</span><span class="s1">)[</span><span class="s3">&quot;train&quot;</span><span class="s1">]</span>
<span class="s0"># label_mapping = {</span>
<span class="s0">#     0: &quot;Negative&quot;, #&quot;Bearish&quot;, </span>
<span class="s0">#     1: &quot;Positive&quot;, # &quot;Bullish&quot;, </span>
<span class="s0">#     2: &quot;Neutral&quot;, #&quot;Neutral&quot;</span>
<span class="s0"># }</span>

<span class="s1">class_labels = ClassLabel(num_classes=</span><span class="s5">3</span><span class="s1">, names = [</span><span class="s3">&quot;bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;neutral&quot;</span><span class="s1">])</span>
<span class="s1">train_dataset = train_dataset.cast_column(</span><span class="s3">&quot;label&quot;</span><span class="s1">,class_labels)</span>
<span class="s1">val_dataset = val_dataset.cast_column(</span><span class="s3">&quot;label&quot;</span><span class="s1">,class_labels)</span>

<span class="s0"># rename the column for compatability with transformers classification head</span>
<span class="s1">train_dataset = train_dataset.rename_column(</span><span class="s3">&quot;label&quot;</span><span class="s1">,</span><span class="s3">&quot;labels&quot;</span><span class="s1">)</span>
<span class="s1">val_dataset = val_dataset.rename_column(</span><span class="s3">&quot;label&quot;</span><span class="s1">,</span><span class="s3">&quot;labels&quot;</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">train_tokenized =train_dataset.map(</span><span class="s2">lambda </span><span class="s1">batch: tokenizer(batch[</span><span class="s3">&quot;text&quot;</span><span class="s1">], padding=</span><span class="s2">True</span><span class="s1">), </span>
                                   <span class="s1">batched=</span><span class="s2">True</span><span class="s1">, batch_size=</span><span class="s5">64</span><span class="s1">)</span>
<span class="s1">print(train_tokenized.features)</span>
<span class="s1">val_tokenized = val_dataset.map(</span><span class="s2">lambda </span><span class="s1">batch: tokenizer(batch[</span><span class="s3">&quot;text&quot;</span><span class="s1">], padding=</span><span class="s2">True</span><span class="s1">), </span>
                                   <span class="s1">batched=</span><span class="s2">True</span><span class="s1">, batch_size=</span><span class="s5">64</span><span class="s1">)</span>
<span class="s1">print(val_tokenized.features)</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">compute_metrics(preds):</span>
    <span class="s1">y_pred = preds.predictions.argmax(axis=-</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">labels = preds.label_ids</span>
    <span class="s1">f1 = f1_score(y_true=labels, y_pred=y_pred, average=</span><span class="s3">'weighted'</span><span class="s1">, sample_weight=val_sample_weights)</span>
    <span class="s1">precision = precision_score(y_true=labels, y_pred=y_pred, average=</span><span class="s3">'weighted'</span><span class="s1">, sample_weight=val_sample_weights)</span>
    <span class="s1">recall = recall_score(y_true=labels, y_pred=y_pred, average=</span><span class="s3">'weighted'</span><span class="s1">, sample_weight=val_sample_weights)</span>
    <span class="s1">accuracy = balanced_accuracy_score(y_true=labels, y_pred=y_pred, sample_weight=val_sample_weights)</span>
    <span class="s1">metrics = {</span>
        <span class="s3">&quot;f1&quot;</span><span class="s1">: f1, </span>
        <span class="s3">&quot;precision&quot;</span><span class="s1">: precision, </span>
        <span class="s3">&quot;recall&quot;</span><span class="s1">: recall, </span>
        <span class="s3">&quot;accuracy&quot;</span><span class="s1">: accuracy,</span>
    <span class="s1">}    </span>
    <span class="s2">return </span><span class="s1">metrics</span>

<span class="s0">#%% 
# artificat_path = &quot;distill_bert_layer_5&quot;</span>
<span class="s1">artificat_path = </span><span class="s3">&quot;distill_bert_layer_4&quot;</span>
<span class="s2">def </span><span class="s1">tune_model(training_params):</span>
    <span class="s1">model = AutoModelForSequenceClassification.from_pretrained(chkpt, num_labels=</span><span class="s5">3</span><span class="s1">).to(device)</span>
    <span class="s2">for </span><span class="s1">encoder_layer, (name,param) </span><span class="s2">in </span><span class="s1">enumerate(model.named_parameters()):</span>
       <span class="s0"># if encoder_layer &lt; 84: # encoder layer 5</span>
       <span class="s2">if </span><span class="s1">encoder_layer &lt; </span><span class="s5">68</span><span class="s1">: </span><span class="s0">#encoder layer 4</span>
           <span class="s1">param.requires_grad = </span><span class="s2">False</span>
       <span class="s2">else</span><span class="s1">:</span>
           <span class="s1">param.requires_grad = </span><span class="s2">True</span>
            
    <span class="s1">training_args = TrainingArguments(</span>
        <span class="s3">&quot;distil_bert_freeze&quot;</span><span class="s1">,</span>
        <span class="s1">eval_strategy=</span><span class="s3">&quot;epoch&quot;</span><span class="s1">,</span>
        <span class="s1">learning_rate = training_params[</span><span class="s3">&quot;learning_rate&quot;</span><span class="s1">],</span>
        <span class="s1">num_train_epochs=training_params[</span><span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">],</span>
        <span class="s1">remove_unused_columns=</span><span class="s2">True</span><span class="s1">,</span>
        <span class="s1">weight_decay= training_params[</span><span class="s3">&quot;weight_decay&quot;</span><span class="s1">],</span>
        <span class="s1">lr_scheduler_type=training_params[</span><span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">],</span>
        <span class="s1">warmup_ratio=training_params[</span><span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">],</span>
        <span class="s1">load_best_model_at_end=</span><span class="s2">True</span><span class="s1">,     </span>
        <span class="s1">metric_for_best_model=</span><span class="s3">&quot;eval_accuracy&quot;</span><span class="s1">, </span>
        <span class="s1">greater_is_better=</span><span class="s2">True</span><span class="s1">,</span>
        <span class="s1">save_strategy=</span><span class="s3">&quot;epoch&quot;</span><span class="s1">,</span>
        <span class="s1">save_total_limit=</span><span class="s5">2</span>
    <span class="s1">)</span>
    <span class="s1">trainer = Trainer(</span>
        <span class="s1">model=model,</span>
        <span class="s1">train_dataset=train_tokenized,</span>
        <span class="s1">eval_dataset=val_tokenized,</span>
        <span class="s1">args=training_args,</span>
        <span class="s1">tokenizer=tokenizer,</span>
        <span class="s1">compute_metrics=compute_metrics,</span>
        <span class="s1">callbacks=[EarlyStoppingCallback(early_stopping_patience=</span><span class="s5">2</span><span class="s1">)]</span>
    <span class="s1">)</span>
   
    <span class="s2">with </span><span class="s1">mlflow.start_run(nested=</span><span class="s2">True</span><span class="s1">) </span><span class="s2">as </span><span class="s1">_:        </span>
        <span class="s1">trainer.train()</span>
        <span class="s1">model.eval()</span>
        <span class="s1">val_predictions = trainer.predict(val_tokenized)</span>
        <span class="s1">model_tokenizer = {</span>
            <span class="s3">&quot;model&quot;</span><span class="s1">: model,</span>
            <span class="s3">&quot;tokenizer&quot;</span><span class="s1">: tokenizer,</span>
        <span class="s1">}</span>
        <span class="s1">metrics = compute_metrics(val_predictions)</span>
        <span class="s1">metrics[</span><span class="s3">&quot;loss&quot;</span><span class="s1">] = -metrics[</span><span class="s3">&quot;accuracy&quot;</span><span class="s1">]</span>
        <span class="s1">print(training_params)</span>
        <span class="s1">print(metrics)</span>
        <span class="s0"># mlflow.log_params(training_args)</span>
        <span class="s1">mlflow.log_metrics(metrics)</span>
        <span class="s1">mlflow.transformers.log_model(transformers_model=model_tokenizer, name=artificat_path, task=</span><span class="s3">&quot;text-classification&quot;</span><span class="s1">)        </span>
        <span class="s1">metrics[</span><span class="s3">&quot;status&quot;</span><span class="s1">] = STATUS_OK</span>
        <span class="s2">return </span><span class="s1">metrics</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">fine_tune_model(ml_flow_run_name, search_space):</span>
    <span class="s2">with </span><span class="s1">mlflow.start_run(run_name=ml_flow_run_name):</span>
        <span class="s0"># Run optimization</span>
        <span class="s1">trials = Trials()</span>
        <span class="s1">best_params = fmin(</span>
            <span class="s1">fn=tune_model,</span>
            <span class="s1">space=search_space,</span>
            <span class="s1">algo=tpe.suggest,</span>
            <span class="s1">max_evals=</span><span class="s5">15</span><span class="s1">,</span>
            <span class="s1">trials=trials,</span>
            <span class="s1">verbose=</span><span class="s2">True</span><span class="s1">,</span>
        <span class="s1">)</span>
        <span class="s0"># Find and log best results</span>
        <span class="s1">best_trial = min(trials.results, key=</span><span class="s2">lambda </span><span class="s1">x: x[</span><span class="s3">&quot;loss&quot;</span><span class="s1">])</span>
        <span class="s0"># Log optimization results</span>
        <span class="s1">mlflow.log_params(best_params)</span>
        <span class="s1">mlflow.log_metrics(</span>
            <span class="s1">{</span>
                <span class="s3">&quot;best_val_log_loss&quot;</span><span class="s1">: best_trial[</span><span class="s3">&quot;loss&quot;</span><span class="s1">],</span>
                 <span class="s3">&quot;best_accuracy&quot;</span><span class="s1">: best_trial[</span><span class="s3">&quot;accuracy&quot;</span><span class="s1">],</span>
                <span class="s3">&quot;best_precision&quot;</span><span class="s1">: best_trial[</span><span class="s3">&quot;precision&quot;</span><span class="s1">],</span>
                <span class="s3">&quot;best_recall&quot; </span><span class="s1">: best_trial[</span><span class="s3">&quot;recall&quot;</span><span class="s1">],</span>
                <span class="s3">&quot;best_f1&quot;</span><span class="s1">: best_trial[</span><span class="s3">&quot;f1&quot;</span><span class="s1">],</span>
                <span class="s3">&quot;total_trials&quot;</span><span class="s1">: len(trials.trials),</span>
                <span class="s3">&quot;optimization_completed&quot;</span><span class="s1">: </span><span class="s5">1</span><span class="s1">,</span>
            <span class="s1">}</span>
        <span class="s1">)</span>
        <span class="s1">print(best_params)</span>
<span class="s0">#%% 
</span><span class="s1">search_space = {</span>
   <span class="s3">&quot;learning_rate&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;learning_rate&quot;</span><span class="s1">, </span><span class="s5">1e-5</span><span class="s1">, </span><span class="s5">5e-5</span><span class="s1">),</span>
    <span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">, </span><span class="s5">2</span><span class="s1">, </span><span class="s5">5</span><span class="s1">),</span>
   <span class="s3">&quot;weight_decay&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;weight_decay&quot;</span><span class="s1">, </span><span class="s5">0.01</span><span class="s1">, </span><span class="s5">0.1</span><span class="s1">),</span>
    <span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">: hp.choice(</span><span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">, [</span><span class="s3">&quot;cosine&quot;</span><span class="s1">, </span><span class="s3">&quot;linear&quot;</span><span class="s1">]),</span>
    <span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">: hp.choice(</span><span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">, [</span><span class="s5">0.0</span><span class="s1">, </span><span class="s5">0.05</span><span class="s1">, </span><span class="s5">0.1</span><span class="s1">]),</span>
<span class="s1">}</span>
<span class="s1">fine_tune_model(</span><span class="s3">&quot;hyper_parameter_search&quot;</span><span class="s1">, search_space)</span>
<span class="s0">#%% 
</span><span class="s1">trained_model = AutoModelForSequenceClassification.from_pretrained(</span><span class="s3">&quot;best_model/distill_bert_layer_5/fine_tune_1/model&quot;</span><span class="s1">)</span>
<span class="s1">trained_model.eval()</span>
<span class="s1">trained_model.to(device)</span>

<span class="s1">saved_tokenizer = AutoTokenizer.from_pretrained(</span><span class="s3">&quot;best_model/distill_bert_layer_5/fine_tune_1/components/tokenizer&quot;</span><span class="s1">)</span>

<span class="s0">#%% 
</span><span class="s1">eval_args = TrainingArguments(</span>
    <span class="s1">output_dir=</span><span class="s3">&quot;./temp_inference&quot;</span><span class="s1">,</span>
    <span class="s1">per_device_eval_batch_size=</span><span class="s5">64</span><span class="s1">,</span>
<span class="s1">)</span>

<span class="s1">trainer = Trainer(</span>
    <span class="s1">model=trained_model,</span>
    <span class="s1">args=eval_args,</span>
    <span class="s1">tokenizer=saved_tokenizer</span>
<span class="s1">)</span>
<span class="s1">output = trainer.predict(val_tokenized)</span>
<span class="s1">metrics = compute_metrics(output)</span>
<span class="s1">metrics</span>
<span class="s0">#%% md 
</span><span class="s1">Now we use the confusion matrix to look into the predicted and true labels. 
We look at it from 2 perspectives. 
1) Normalize=true(row-wise, based on true labels), out of all the &quot;Bearish&quot; tweets, how much did the model correctly predict as &quot;Bearish&quot;. This nothing but the recall. 
2) Normalize = pred(column-wise, based on predicted labels), out of all the &quot;Bearish&quot; predictions made by the model, how much are actually &quot;Bearish&quot;. This is the precision of the model. When mu model makes a prediction as &quot;Bearish&quot;, how confident can i be that the tweet is actually &quot;Bearish&quot;. 
</span><span class="s0">#%% 
</span><span class="s1">y_pred = output.predictions.argmax(axis=-</span><span class="s5">1</span><span class="s1">)</span>
<span class="s1">labels = output.label_ids</span>

<span class="s1">cm = confusion_matrix(labels, y_pred, normalize=</span><span class="s3">&quot;true&quot;</span><span class="s1">)</span>
<span class="s1">disp = ConfusionMatrixDisplay(confusion_matrix=cm,</span>
                              <span class="s1">display_labels=[</span><span class="s3">&quot;Bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;Bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;Neutral&quot;</span><span class="s1">])</span>
<span class="s1">disp.plot()</span>
<span class="s1">plt.show()</span>
<span class="s0">#%% 
</span><span class="s1">cm = confusion_matrix(labels, y_pred, normalize=</span><span class="s3">&quot;pred&quot;</span><span class="s1">)</span>
<span class="s1">disp = ConfusionMatrixDisplay(confusion_matrix=cm,</span>
                              <span class="s1">display_labels=[</span><span class="s3">&quot;Bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;Bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;Neutral&quot;</span><span class="s1">])</span>
<span class="s1">disp.plot()</span>
<span class="s1">plt.show()</span>
<span class="s0">#%% 
</span><span class="s1">search_space_2 = {</span>
   <span class="s3">&quot;learning_rate&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;learning_rate&quot;</span><span class="s1">, </span><span class="s5">3e-5</span><span class="s1">, </span><span class="s5">5e-5</span><span class="s1">),</span>
    <span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">, </span><span class="s5">2</span><span class="s1">, </span><span class="s5">4</span><span class="s1">),</span>
   <span class="s3">&quot;weight_decay&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;weight_decay&quot;</span><span class="s1">, </span><span class="s5">0.06</span><span class="s1">, </span><span class="s5">0.08</span><span class="s1">),</span>
    <span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">: hp.choice(</span><span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">, [</span><span class="s3">&quot;linear&quot;</span><span class="s1">]),</span>
    <span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">: hp.choice(</span><span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">, [</span><span class="s5">0.0</span><span class="s1">, </span><span class="s5">0.05</span><span class="s1">, </span><span class="s5">0.1</span><span class="s1">]),</span>
<span class="s1">}</span>
<span class="s1">fine_tune_model(</span><span class="s3">&quot;hyper_parameter_search_step_2&quot;</span><span class="s1">, search_space_2)</span>
<span class="s1">;</span>
<span class="s0">#%% 
</span><span class="s1">trained_model = AutoModelForSequenceClassification.from_pretrained(</span>
    <span class="s3">&quot;../twitter_fsa/best_model/distill_bert_layer_5/fine_tune_2/model&quot;</span><span class="s1">)</span>
<span class="s1">trained_model.eval()</span>
<span class="s1">trained_model.to(device)</span>

<span class="s1">saved_tokenizer = AutoTokenizer.from_pretrained(</span><span class="s3">&quot;../twitter_fsa/best_model/distill_bert_layer_5/fine_tune_2/components/tokenizer&quot;</span><span class="s1">)</span>

<span class="s1">eval_args = TrainingArguments(</span>
    <span class="s1">output_dir=</span><span class="s3">&quot;./temp_inference&quot;</span><span class="s1">,</span>
    <span class="s1">per_device_eval_batch_size=</span><span class="s5">64</span><span class="s1">,</span>
<span class="s1">)</span>

<span class="s1">trainer = Trainer(</span>
    <span class="s1">model=trained_model,</span>
    <span class="s1">args=eval_args,</span>
    <span class="s1">tokenizer=saved_tokenizer</span>
<span class="s1">)</span>
<span class="s1">output = trainer.predict(val_tokenized)</span>
<span class="s1">metrics = compute_metrics(output)</span>
<span class="s1">metrics</span>
<span class="s0">#%% 
</span><span class="s1">y_pred = output.predictions.argmax(axis=-</span><span class="s5">1</span><span class="s1">)</span>
<span class="s1">labels = output.label_ids</span>

<span class="s1">cm = confusion_matrix(labels, y_pred, normalize=</span><span class="s3">&quot;true&quot;</span><span class="s1">)</span>
<span class="s1">disp = ConfusionMatrixDisplay(confusion_matrix=cm,</span>
                              <span class="s1">display_labels=[</span><span class="s3">&quot;Bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;Bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;Neutral&quot;</span><span class="s1">])</span>
<span class="s1">disp.plot()</span>
<span class="s1">plt.show()</span>
<span class="s0">#%% 
</span><span class="s1">y_pred = output.predictions.argmax(axis=-</span><span class="s5">1</span><span class="s1">)</span>
<span class="s1">labels = output.label_ids</span>

<span class="s1">cm = confusion_matrix(labels, y_pred, normalize=</span><span class="s3">&quot;pred&quot;</span><span class="s1">)</span>
<span class="s1">disp = ConfusionMatrixDisplay(confusion_matrix=cm,</span>
                              <span class="s1">display_labels=[</span><span class="s3">&quot;Bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;Bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;Neutral&quot;</span><span class="s1">])</span>
<span class="s1">disp.plot()</span>
<span class="s1">plt.show()</span>
<span class="s0">#%% 
</span><span class="s1">search_space_unfreeze_layer_4 = {</span>
   <span class="s3">&quot;learning_rate&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;learning_rate&quot;</span><span class="s1">, </span><span class="s5">1e-5</span><span class="s1">, </span><span class="s5">5e-5</span><span class="s1">),</span>
    <span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;num_train_epochs&quot;</span><span class="s1">, </span><span class="s5">2</span><span class="s1">, </span><span class="s5">5</span><span class="s1">),</span>
   <span class="s3">&quot;weight_decay&quot;</span><span class="s1">: hp.uniform(</span><span class="s3">&quot;weight_decay&quot;</span><span class="s1">, </span><span class="s5">0.01</span><span class="s1">, </span><span class="s5">0.1</span><span class="s1">),</span>
    <span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">: hp.choice(</span><span class="s3">&quot;lr_scheduler&quot;</span><span class="s1">, [</span><span class="s3">&quot;cosine&quot;</span><span class="s1">, </span><span class="s3">&quot;linear&quot;</span><span class="s1">]),</span>
    <span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">: hp.choice(</span><span class="s3">&quot;warmup_ratio&quot;</span><span class="s1">, [</span><span class="s5">0.0</span><span class="s1">, </span><span class="s5">0.05</span><span class="s1">, </span><span class="s5">0.1</span><span class="s1">]),</span>
<span class="s1">}</span>
<span class="s1">fine_tune_model(</span><span class="s3">&quot;unfreeze_layer_4&quot;</span><span class="s1">, search_space_unfreeze_layer_4)</span>
<span class="s0">#%% 
</span><span class="s1">trained_model = AutoModelForSequenceClassification.from_pretrained(</span><span class="s3">&quot;best_model/distill_bert_layer_4/fine_tune_1/model&quot;</span><span class="s1">)</span>
<span class="s1">trained_model.eval()</span>
<span class="s1">trained_model.to(device)</span>

<span class="s1">saved_tokenizer = AutoTokenizer.from_pretrained(</span><span class="s3">&quot;best_model/distill_bert_layer_4/fine_tune_1/components/tokenizer&quot;</span><span class="s1">)</span>

<span class="s1">eval_args = TrainingArguments(</span>
    <span class="s1">output_dir=</span><span class="s3">&quot;./temp_inference&quot;</span><span class="s1">,</span>
    <span class="s1">per_device_eval_batch_size=</span><span class="s5">64</span><span class="s1">,</span>
<span class="s1">)</span>

<span class="s1">trainer = Trainer(</span>
    <span class="s1">model=trained_model,</span>
    <span class="s1">args=eval_args,</span>
    <span class="s1">tokenizer=saved_tokenizer</span>
<span class="s1">)</span>
<span class="s1">output = trainer.predict(val_tokenized)</span>
<span class="s1">metrics = compute_metrics(output)</span>
<span class="s1">metrics</span>
<span class="s0">#%% 
</span><span class="s1">y_pred = output.predictions.argmax(axis=-</span><span class="s5">1</span><span class="s1">)</span>
<span class="s1">labels = output.label_ids</span>

<span class="s1">cm = confusion_matrix(labels, y_pred, normalize=</span><span class="s3">&quot;true&quot;</span><span class="s1">)</span>
<span class="s1">disp = ConfusionMatrixDisplay(confusion_matrix=cm,</span>
                              <span class="s1">display_labels=[</span><span class="s3">&quot;Bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;Bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;Neutral&quot;</span><span class="s1">])</span>
<span class="s1">disp.plot()</span>
<span class="s1">plt.show()</span>
<span class="s0">#%% 
</span><span class="s1">y_pred = output.predictions.argmax(axis=-</span><span class="s5">1</span><span class="s1">)</span>
<span class="s1">labels = output.label_ids</span>

<span class="s1">cm = confusion_matrix(labels, y_pred, normalize=</span><span class="s3">&quot;pred&quot;</span><span class="s1">)</span>
<span class="s1">disp = ConfusionMatrixDisplay(confusion_matrix=cm,</span>
                              <span class="s1">display_labels=[</span><span class="s3">&quot;Bearish&quot;</span><span class="s1">, </span><span class="s3">&quot;Bullish&quot;</span><span class="s1">, </span><span class="s3">&quot;Neutral&quot;</span><span class="s1">])</span>
<span class="s1">disp.plot()</span>
<span class="s1">plt.show()</span></pre>
</body>
</html>