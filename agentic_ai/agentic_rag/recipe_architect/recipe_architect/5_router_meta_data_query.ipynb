{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-18T00:14:55.994598Z",
     "start_time": "2026-02-18T00:14:49.062541Z"
    }
   },
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "from typing import Optional\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from config import set_environment"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:14:57.482754Z",
     "start_time": "2026-02-18T00:14:57.477175Z"
    }
   },
   "cell_type": "code",
   "source": "set_environment()",
   "id": "c25a5e8c27d827b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:02.733224Z",
     "start_time": "2026-02-18T00:21:02.728797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = \"data\"\n",
    "collection_name = \"recipe_dataset\""
   ],
   "id": "1d2def323dc9b133",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:08.375290Z",
     "start_time": "2026-02-18T00:21:03.983057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chroma_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "                                   model_kwargs={'device': \"cuda\"},\n",
    "                                   encode_kwargs={'normalize_embeddings': False})\n",
    "\n",
    "re_rank_model =  CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ],
   "id": "361df80eeddc82f9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4638cedc38fa4729abbd428ee614ee8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1mBertModel LOAD REPORT\u001B[0m from: sentence-transformers/all-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "099e6c9a3b1649629c4dba70aa5ae03d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1mBertForSequenceClassification LOAD REPORT\u001B[0m from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:14:59.951013Z",
     "start_time": "2026-02-18T00:14:59.945780Z"
    }
   },
   "cell_type": "code",
   "source": "mistral_llm = ChatMistralAI(model=\"mistral-small-latest\")",
   "id": "9b20d34806ab5c44",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:15:01.396446Z",
     "start_time": "2026-02-18T00:15:01.129248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_ollama =  ChatOllama(\n",
    "    model = \"cogito-2.1:671b-cloud\",\n",
    "    base_url=\"https://ollama.com\",\n",
    "    headers={\"Authorization\": f\"Bearer {os.environ['OLLAMA_API_KEY']}\"},\n",
    "    temperature=0\n",
    ")"
   ],
   "id": "6391b0b4fdf67daf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:15:02.647310Z",
     "start_time": "2026-02-18T00:15:02.300843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat_groq = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    # reasoning_format=\"parsed\",\n",
    ")"
   ],
   "id": "513b33f5a636eef3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:10.832541Z",
     "start_time": "2026-02-18T00:21:10.750030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client_settings = chromadb.config.Settings(\n",
    "    anonymized_telemetry=False,\n",
    "    is_persistent=True\n",
    ")\n",
    "client = chromadb.PersistentClient(path=db_path, settings=client_settings)\n",
    "collections = client.list_collections()\n",
    "collections"
   ],
   "id": "9678343ee8c09b2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=recipe_dataset)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:12.401738Z",
     "start_time": "2026-02-18T00:21:12.241105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collection = client.get_collection(name=collection_name)\n",
    "collection.count()"
   ],
   "id": "af8be7ae63cb1df5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:08.406651Z",
     "start_time": "2026-02-18T00:22:06.637883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/bm25_retriever.pkl\", \"rb\") as f:\n",
    "    bm25_retriever = pickle.load(f)\n",
    "print(\"Retriever loaded from disk.\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name = \"recipe_dataset\",\n",
    "    embedding_function = chroma_embeddings,\n",
    "    persist_directory=\"data\",\n",
    "    client_settings=client_settings,\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "semantic_retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})\n",
    "\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers = [semantic_retriever, bm25_retriever],\n",
    "    weights = [0.6,0.4]\n",
    ")"
   ],
   "id": "1a75ad126970899f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever loaded from disk.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:39:07.657662Z",
     "start_time": "2026-02-18T00:39:07.647462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RouteQuery(BaseModel):\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "structured_llm_router = mistral_llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are the Router for a Recipe Intelligence System. \n",
    "Your goal is to route user queries to the most efficient data source.\n",
    "\n",
    "### DATA SOURCES:\n",
    "1. 'vector_store': Contains 77,000 recipes with structured metadata (ingredients, directions, category, dietary restrictions.).\n",
    "2. 'web_search': Best for general culinary science, history of dishes, basic cooking techniques.\n",
    "\n",
    "### ROUTING RULES:\n",
    "- Route to 'vector_store' if:\n",
    "    - User asks for a meal recommendation or recipes with dietary restrictions or food preferences. (e.g., \"Find me a quick breakfast\", \"vegan pasta\", \"spicy noodles\" etc).\n",
    "    - User asks about a specific recipe title or ingredient combo\n",
    "    - User asks \"How is an ingredient [X] is used in [Recipe Y]?\"\n",
    "    - User asks \"How to make [Dish Name]\" or \"Recipe for [Dish Name]\"\n",
    "- Route to 'generic_search' if:\n",
    "    - User asks for basic cooking techniques (e.g., How to boil an egg\" etc).\n",
    "    - User asks for food science (e.g., \"Smoking point of oil\" etc).\n",
    "    - User asks for general food facts (e.g., \"Where did Butter chicken originate?\" etc).\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router"
   ],
   "id": "d6a0ff3100cc26c6",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:42:01.330461Z",
     "start_time": "2026-02-18T00:41:55.963741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"How long simmering double boiler?\"}\n",
    "    )\n",
    ")"
   ],
   "id": "fc38febe76de5642",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:17.603893Z",
     "start_time": "2026-02-18T00:21:17.592501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RecipeSearch(BaseModel):\n",
    "    # content_search: Optional[str] = Field(\n",
    "    #     None,\n",
    "    #     description=\"Similarity search query.\",\n",
    "    # )\n",
    "    # title_search: Optional[str] = Field(\n",
    "    #     None,\n",
    "    #     description=(\n",
    "    #         \"Alternate version of the content search query to apply to recipe titles. \"\n",
    "    #         \"Should be succinct and only include key words that could be in a recipe \"\n",
    "    #         \"title. Use only if user asks explicitly for a specific recipe.\"\n",
    "    #     ),\n",
    "    # )\n",
    "                      \n",
    "\n",
    "    category: Optional[Literal[\n",
    "        \"Baking\",\"Breads\", \"Condiments and sides\" ,\"Drinks\", \"Grains and Pasta\" ,\n",
    "        \"Mains\", \"Other\", \"Salads\", \"Soup\", \"Sweet\", \"Vegan\"\n",
    "    ]] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Indicates the category of the recipe to search for. \"\n",
    "            \"Should be one of the provided values.\"\n",
    "            \"MANDATORY: Select the best category from the list if mentioned. If not mentioned, return none.\"\n",
    "            \"Example: 'sourdough' -> Breads, 'cupcake' -> Baking, 'lentil soup' -> Soup. etc\"\n",
    "        )\n",
    "    )\n",
    "    is_nut_free: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Nut free filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_gluten_free: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Gluten free filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_dairy_free: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Dairy free filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_spicy_food: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Spicy food filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "                     \n",
    "    is_comfort_food: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Comfort food filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_light_food: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Light food filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_hearty_food: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Hearty food filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_healthy: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Healthy food filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "   \n",
    "                     \n",
    "    is_breakfast: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Breakfast filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_lunch: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Lunch filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_dinner: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Dinner filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_quick: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Quick filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    \n",
    "    is_no_oven: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"No oven filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    \n",
    "    is_slow_cooker: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Slow cooker filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_air_fryer: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Air fryer filter. Only use if explicitly specified.\",\n",
    "    )\n",
    "    is_one_pot: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"One pot filter. Only use if explicitly specified.\",\n",
    "    )"
   ],
   "id": "93fa87e473ccf70e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:23.217875Z",
     "start_time": "2026-02-18T00:21:23.212446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system = \"\"\"You are an expert at converting user questions into database queries.\n",
    "You have access to a database of recipes. \n",
    "Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ],
   "id": "3a8596c6ada3ba2d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:46.264753Z",
     "start_time": "2026-02-18T00:21:46.258902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "structured_llm = chat_groq.with_structured_output(RecipeSearch)\n",
    "query_analyzer = prompt | structured_llm"
   ],
   "id": "311b6f00843c6e30",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:48.998056Z",
     "start_time": "2026-02-18T00:21:47.919335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# question = \"vegan gluten free pasta nut free\"\n",
    "# question = \"quick and healthy breakfast\"\n",
    "# question = \"lunch no-cook salad with citrus and beet\"\n",
    "# question = \"What is the use of corn in Tamale Bake?\"\n",
    "# question = \"How many eggs are required in Mom's Meat Loaf recipe?\"\n",
    "question = \"How to boil an egg?\"\n",
    "result = query_analyzer.invoke({\"question\": question})\n",
    "result"
   ],
   "id": "ee8f6ced8ef66073",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecipeSearch(category=None, is_nut_free=None, is_gluten_free=None, is_dairy_free=None, is_spicy_food=None, is_comfort_food=None, is_light_food=None, is_hearty_food=None, is_healthy=None, is_breakfast=None, is_lunch=None, is_dinner=None, is_quick=1, is_no_oven=1, is_slow_cooker=None, is_air_fryer=None, is_one_pot=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:52.310934Z",
     "start_time": "2026-02-18T00:21:52.306404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meta_data_filters = result.model_dump(exclude_none=True)\n",
    "if meta_data_filters.get(\"category\") == \"Other\" :\n",
    "    del meta_data_filters[\"category\"]\n",
    "print(meta_data_filters)"
   ],
   "id": "2a6bc113f7b0c12b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_quick': 1, 'is_no_oven': 1}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:31:19.442112Z",
     "start_time": "2026-02-18T00:31:19.403608Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ce1ad05f44e5a658",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[45]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m meta_data_filters = \u001B[43mmeta_data_filters\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyError\u001B[39m: 0"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:21:56.615482Z",
     "start_time": "2026-02-18T00:21:56.606731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filter_dict = {}\n",
    "and_list = []\n",
    "if len(meta_data_filters) > 1:\n",
    "   filter_dict[\"$and\"] = [{f:meta_data_filters[f]} for f in meta_data_filters]\n",
    "elif len(meta_data_filters) == 1:\n",
    "    filter_dict = meta_data_filters\n",
    "else:\n",
    "    filter_dict = None\n",
    "filter_dict"
   ],
   "id": "ef0ba7e100b7090e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$and': [{'is_quick': 1}, {'is_no_oven': 1}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:31:48.114205Z",
     "start_time": "2026-02-18T00:31:48.106540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filter_dict[\"$and\"].pop(0)\n",
    "filter_dict"
   ],
   "id": "e4e9f026fd00946",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$and': [{'is_no_oven': 1}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:31:52.346164Z",
     "start_time": "2026-02-18T00:31:51.579654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "semantic_retriever.search_kwargs[\"filter\"] = filter_dict\n",
    "docs = hybrid_retriever.invoke(question)\n",
    "len(docs)"
   ],
   "id": "9b0ef5c0cdd66104",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected where value for $and or $or to be a list with at least two where expressions, got [{'is_no_oven': 1}] in query.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m semantic_retriever.search_kwargs[\u001B[33m\"\u001B[39m\u001B[33mfilter\u001B[39m\u001B[33m\"\u001B[39m] = filter_dict\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m docs = \u001B[43mhybrid_retriever\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[38;5;28mlen\u001B[39m(docs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_classic\\retrievers\\ensemble.py:114\u001B[39m, in \u001B[36mEnsembleRetriever.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    107\u001B[39m run_manager = callback_manager.on_retriever_start(\n\u001B[32m    108\u001B[39m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    109\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m    110\u001B[39m     name=config.get(\u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.get_name(),\n\u001B[32m    111\u001B[39m     **kwargs,\n\u001B[32m    112\u001B[39m )\n\u001B[32m    113\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrank_fusion\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    116\u001B[39m     run_manager.on_retriever_error(e)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_classic\\retrievers\\ensemble.py:223\u001B[39m, in \u001B[36mEnsembleRetriever.rank_fusion\u001B[39m\u001B[34m(self, query, run_manager, config)\u001B[39m\n\u001B[32m    209\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Rank fusion.\u001B[39;00m\n\u001B[32m    210\u001B[39m \n\u001B[32m    211\u001B[39m \u001B[33;03mRetrieve the results of the retrievers and use rank_fusion_func to get\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    220\u001B[39m \u001B[33;03m    A list of reranked documents.\u001B[39;00m\n\u001B[32m    221\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    222\u001B[39m \u001B[38;5;66;03m# Get the results of all retrievers.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m223\u001B[39m retriever_docs = \u001B[43m[\u001B[49m\n\u001B[32m    224\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretriever\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    225\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    226\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    227\u001B[39m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    228\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mretriever_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[43m+\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[32;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    229\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    231\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretriever\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mretrievers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    232\u001B[39m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    234\u001B[39m \u001B[38;5;66;03m# Enforce that retrieved docs are Documents for each list in retriever_docs\u001B[39;00m\n\u001B[32m    235\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(retriever_docs)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_classic\\retrievers\\ensemble.py:224\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    209\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Rank fusion.\u001B[39;00m\n\u001B[32m    210\u001B[39m \n\u001B[32m    211\u001B[39m \u001B[33;03mRetrieve the results of the retrievers and use rank_fusion_func to get\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    220\u001B[39m \u001B[33;03m    A list of reranked documents.\u001B[39;00m\n\u001B[32m    221\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    222\u001B[39m \u001B[38;5;66;03m# Get the results of all retrievers.\u001B[39;00m\n\u001B[32m    223\u001B[39m retriever_docs = [\n\u001B[32m--> \u001B[39m\u001B[32m224\u001B[39m     \u001B[43mretriever\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    225\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    226\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    227\u001B[39m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    228\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mretriever_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[43m+\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[32;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    229\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    231\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, retriever \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m.retrievers)\n\u001B[32m    232\u001B[39m ]\n\u001B[32m    234\u001B[39m \u001B[38;5;66;03m# Enforce that retrieved docs are Documents for each list in retriever_docs\u001B[39;00m\n\u001B[32m    235\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(retriever_docs)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:222\u001B[39m, in \u001B[36mBaseRetriever.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    220\u001B[39m kwargs_ = kwargs \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._expects_other_args \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[32m    221\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._new_arg_supported:\n\u001B[32m--> \u001B[39m\u001B[32m222\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_relevant_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    223\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs_\u001B[49m\n\u001B[32m    224\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    225\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    226\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._get_relevant_documents(\u001B[38;5;28minput\u001B[39m, **kwargs_)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1045\u001B[39m, in \u001B[36mVectorStoreRetriever._get_relevant_documents\u001B[39m\u001B[34m(self, query, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1043\u001B[39m kwargs_ = \u001B[38;5;28mself\u001B[39m.search_kwargs | kwargs\n\u001B[32m   1044\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.search_type == \u001B[33m\"\u001B[39m\u001B[33msimilarity\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1045\u001B[39m     docs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvectorstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43msimilarity_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1046\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.search_type == \u001B[33m\"\u001B[39m\u001B[33msimilarity_score_threshold\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1047\u001B[39m     docs_and_similarities = (\n\u001B[32m   1048\u001B[39m         \u001B[38;5;28mself\u001B[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001B[32m   1049\u001B[39m             query, **kwargs_\n\u001B[32m   1050\u001B[39m         )\n\u001B[32m   1051\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:748\u001B[39m, in \u001B[36mChroma.similarity_search\u001B[39m\u001B[34m(self, query, k, filter, **kwargs)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msimilarity_search\u001B[39m(\n\u001B[32m    731\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    732\u001B[39m     query: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    735\u001B[39m     **kwargs: Any,\n\u001B[32m    736\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[Document]:\n\u001B[32m    737\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Run similarity search with Chroma.\u001B[39;00m\n\u001B[32m    738\u001B[39m \n\u001B[32m    739\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    746\u001B[39m \u001B[33;03m        List of documents most similar to the query text.\u001B[39;00m\n\u001B[32m    747\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m748\u001B[39m     docs_and_scores = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msimilarity_search_with_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    749\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    750\u001B[39m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    751\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    752\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    753\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    754\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [doc \u001B[38;5;28;01mfor\u001B[39;00m doc, _ \u001B[38;5;129;01min\u001B[39;00m docs_and_scores]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:849\u001B[39m, in \u001B[36mChroma.similarity_search_with_score\u001B[39m\u001B[34m(self, query, k, filter, where_document, **kwargs)\u001B[39m\n\u001B[32m    847\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    848\u001B[39m     query_embedding = \u001B[38;5;28mself\u001B[39m._embedding_function.embed_query(query)\n\u001B[32m--> \u001B[39m\u001B[32m849\u001B[39m     results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__query_collection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    850\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mquery_embedding\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    851\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_results\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    852\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    853\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwhere_document\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere_document\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    854\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    855\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    857\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _results_to_docs_and_scores(results)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_core\\utils\\utils.py:51\u001B[39m, in \u001B[36mxor_args.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     45\u001B[39m     msg = (\n\u001B[32m     46\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mExactly one argument in each of the following\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     47\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m groups must be defined:\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     48\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(invalid_group_names)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     49\u001B[39m     )\n\u001B[32m     50\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:477\u001B[39m, in \u001B[36mChroma.__query_collection\u001B[39m\u001B[34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001B[39m\n\u001B[32m    449\u001B[39m \u001B[38;5;129m@xor_args\u001B[39m((\u001B[33m\"\u001B[39m\u001B[33mquery_texts\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mquery_embeddings\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m    450\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__query_collection\u001B[39m(\n\u001B[32m    451\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    457\u001B[39m     **kwargs: Any,\n\u001B[32m    458\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[Document] | chromadb.QueryResult:\n\u001B[32m    459\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Query the chroma collection.\u001B[39;00m\n\u001B[32m    460\u001B[39m \n\u001B[32m    461\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    475\u001B[39m \u001B[33;03m    See more: https://docs.trychroma.com/reference/py-collection#query\u001B[39;00m\n\u001B[32m    476\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m477\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_collection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_texts\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_texts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_results\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwhere_document\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere_document\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:241\u001B[39m, in \u001B[36mCollection.query\u001B[39m\u001B[34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001B[39m\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mquery\u001B[39m(\n\u001B[32m    183\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    184\u001B[39m     query_embeddings: Optional[\n\u001B[32m   (...)\u001B[39m\u001B[32m    201\u001B[39m     ],\n\u001B[32m    202\u001B[39m ) -> QueryResult:\n\u001B[32m    203\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Query for the K nearest neighbor records in the collection.\u001B[39;00m\n\u001B[32m    204\u001B[39m \n\u001B[32m    205\u001B[39m \u001B[33;03m    This is a batch query API. Multiple queries can be performed at once\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    238\u001B[39m \u001B[33;03m        ValueError: If multiple query input types are provided.\u001B[39;00m\n\u001B[32m    239\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m241\u001B[39m     query_request = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_and_prepare_query_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    242\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    243\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_texts\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_texts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    244\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_images\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_images\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    245\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_uris\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_uris\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    246\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_results\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwhere_document\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere_document\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    250\u001B[39m \u001B[43m        \u001B[49m\u001B[43minclude\u001B[49m\u001B[43m=\u001B[49m\u001B[43minclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    251\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    253\u001B[39m     query_results = \u001B[38;5;28mself\u001B[39m._client._query(\n\u001B[32m    254\u001B[39m         collection_id=\u001B[38;5;28mself\u001B[39m.id,\n\u001B[32m    255\u001B[39m         ids=query_request[\u001B[33m\"\u001B[39m\u001B[33mids\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    262\u001B[39m         database=\u001B[38;5;28mself\u001B[39m.database,\n\u001B[32m    263\u001B[39m     )\n\u001B[32m    265\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._transform_query_response(\n\u001B[32m    266\u001B[39m         response=query_results, include=query_request[\u001B[33m\"\u001B[39m\u001B[33minclude\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    267\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:103\u001B[39m, in \u001B[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001B[32m    102\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    104\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    105\u001B[39m         msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:329\u001B[39m, in \u001B[36mCollectionCommon._validate_and_prepare_query_request\u001B[39m\u001B[34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;66;03m# Validate\u001B[39;00m\n\u001B[32m    328\u001B[39m validate_base_record_set(record_set=query_records)\n\u001B[32m--> \u001B[39m\u001B[32m329\u001B[39m \u001B[43mvalidate_filter_set\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilter_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    330\u001B[39m validate_include(include=include)\n\u001B[32m    331\u001B[39m validate_n_results(n_results=n_results)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:555\u001B[39m, in \u001B[36mvalidate_filter_set\u001B[39m\u001B[34m(filter_set)\u001B[39m\n\u001B[32m    553\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mvalidate_filter_set\u001B[39m(filter_set: FilterSet) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    554\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m filter_set[\u001B[33m\"\u001B[39m\u001B[33mwhere\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m555\u001B[39m         \u001B[43mvalidate_where\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilter_set\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mwhere\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    556\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m filter_set[\u001B[33m\"\u001B[39m\u001B[33mwhere_document\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    557\u001B[39m         validate_where_document(filter_set[\u001B[33m\"\u001B[39m\u001B[33mwhere_document\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\aiML\\NLP\\llms\\rag\\recipe_architect\\recipe_architect\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:1210\u001B[39m, in \u001B[36mvalidate_where\u001B[39m\u001B[34m(where)\u001B[39m\n\u001B[32m   1206\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1207\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected where value for $and or $or to be a list of where expressions, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1208\u001B[39m     )\n\u001B[32m   1209\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(value) <= \u001B[32m1\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1210\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1211\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected where value for $and or $or to be a list with at least two where expressions, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1212\u001B[39m     )\n\u001B[32m   1213\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m where_expression \u001B[38;5;129;01min\u001B[39;00m value:\n\u001B[32m   1214\u001B[39m     validate_where(where_expression)\n",
      "\u001B[31mValueError\u001B[39m: Expected where value for $and or $or to be a list with at least two where expressions, got [{'is_no_oven': 1}] in query."
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:17.725520Z",
     "start_time": "2026-02-18T00:22:17.719537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filter_names = {\n",
    "    'is_nut_free' : [\"Contains nuts\", \"Nut free\"],\n",
    "    'is_gluten_free': [\"Contains Gluten\", \"Gluten free\"],\n",
    "    'is_dairy_free' : [\"Contains Dairy\", \"Dairy free\"], \n",
    "    'is_spicy_food': [\"Not spicy food\", \"Spicy food\"], \n",
    "    'is_comfort_food': [\"Not comfort food\", \"Comfort food\"], \n",
    "    'is_light_food': [\"Not light food\", \"Light food\"],     \n",
    "    'is_hearty_food': [\"Not hearty food\", \"Hearty food\"], \n",
    "    'is_healthy': [\"Not healthy food\", \"Healthy food\"], \n",
    "    'is_breakfast': [\"Not breakfast\", \"Breakfast\"], \n",
    "    'is_lunch': [\"Not lunch\", \"Lunch\"], \n",
    "    'is_dinner': [\"Not Dinner\", \"Dinner\"],\n",
    "    'is_no_oven': [\"Uses Oven\", \"No oven\"],\n",
    "    'is_slow_cooker': [\"Uses Slow Cooker\", \"No slow cooker\"],\n",
    "    'is_air_fryer': [\"Uses air fryer\", \"No air fryer\"], \n",
    "    'is_one_pot': [\"Uses One pot\", \"No One pot\"],\n",
    "    'is_quick': [\"Not quick\", \"Quick\"],\n",
    "}    "
   ],
   "id": "36f5cc569606df25",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:19.895403Z",
     "start_time": "2026-02-18T00:22:19.887357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formatted_docs = []\n",
    "for doc in docs:\n",
    "        filter_data = \"\"\n",
    "        if meta_data_filters is not None and len(meta_data_filters) > 0:\n",
    "             for f in meta_data_filters:\n",
    "                if f in filter_names:\n",
    "                    filter_data += f\"{filter_names[f][doc.metadata[f]]}, \"\n",
    "                else:\n",
    "                     filter_data += f\"{f} : {doc.metadata[f]}, \"\n",
    "        header = f\"--- STATUS: {filter_data} ---\"           \n",
    "        formatted_content = f\"{header}\\n{doc.page_content}\"\n",
    "        print(header + \"\\n\" + doc.metadata[\"title\"])\n",
    "        formatted_docs.append(formatted_content)"
   ],
   "id": "c660f17fc65ee084",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STATUS: Quick, No oven,  ---\n",
      "Boiled Custard\n",
      "--- STATUS: Quick, No oven,  ---\n",
      "Basic Eggs Breakfast Set\n",
      "--- STATUS: Quick, No oven,  ---\n",
      "Huani\n",
      "--- STATUS: Quick, No oven,  ---\n",
      "Drowned Eggs\n",
      "--- STATUS: Quick, No oven,  ---\n",
      "Boiled Egg Salad Recipe\n",
      "--- STATUS: Not quick, No oven,  ---\n",
      "How To Make Proper Water\n",
      "--- STATUS: Not quick, No oven,  ---\n",
      "Snow Cream\n",
      "--- STATUS: Not quick, No oven,  ---\n",
      "How To Prepare Fresh Green Beans\n",
      "--- STATUS: Not quick, No oven,  ---\n",
      "Chilled Pasta with Scallops and Tomatoes\n",
      "--- STATUS: Not quick, Uses Oven,  ---\n",
      "\"My They'Re Good, How Did You Make Them\" Brownies\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:22.362202Z",
     "start_time": "2026-02-18T00:22:22.356342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def re_rank(query, query_result, check_score=True):\n",
    "    # cross-encoder re-ranker\n",
    "    ranks = re_rank_model.rank(query, query_result)\n",
    "    if ranks[0][\"score\"] < 0:\n",
    "        return [query_result[ranks[0][\"corpus_id\"]]]\n",
    "    reranked_docs = []\n",
    "    for rank_score in ranks:\n",
    "        if check_score and rank_score[\"score\"] < 0:\n",
    "            continue\n",
    "        else:\n",
    "            reranked_docs.append(query_result[rank_score[\"corpus_id\"]])\n",
    "    return reranked_docs"
   ],
   "id": "21681d29e8f51d04",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:24.583861Z",
     "start_time": "2026-02-18T00:22:24.261742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "re_ranked_docs = re_rank(question, formatted_docs, check_score=True)\n",
    "print(f\"number of filtered docs: {len(re_ranked_docs)}\")\n",
    "print(re_ranked_docs)"
   ],
   "id": "446f5d790568126",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of filtered docs: 3\n",
      "['--- STATUS: Quick, No oven,  ---\\n# Title: Huani\\n### Ingredients:\\n1. 2 hard-boiled eggs\\n2. 1 pinch season salt\\n### Directions: \\n1. Boil the eggs and mash them in a food masher.\\n2. Add the season salt and stir.\\n3. Enjoy!', '--- STATUS: Quick, No oven,  ---\\n# Title: Boiled Custard\\n### Ingredients:\\n1. 4 cups milk\\n2. 6 large egg yolks\\n3. 3/4 cup sugar\\n4. 2 tablespoons cornstarch\\n5. Dash of salt\\n6. 2 teaspoons vanilla extract\\n7. Ground nutmeg\\n### Directions: \\n1. Pour milk into top of a double boiler; bring water to a boil. Heat milk until tiny bubbles begin to appear around edges of pan. Remove from heat, and set aside.\\n2. Beat egg yolks with a wire whisk until frothy. Add sugar, cornstarch, and salt, beating until thickened. Gradually stir about 1 cup hot milk into yolk mixture; add to remaining milk, stirring constantly.\\n3. Cook custard mixture in double boiler over low heat 25 minutes or until mixture is thickened and a candy thermometer registers 180, stirring occasionally. (Do not boil.) Stir in vanilla. Serve warm or cold; sprinkle with nutmeg.', '--- STATUS: Quick, No oven,  ---\\n# Title: Boiled Egg Salad Recipe\\n### Ingredients:\\n1. 4 hard-boiled Large eggs, minced\\n2. 1 sm. can pineapple chunks, liquid removed\\n3. 1/4 head crisp lettuce, torn into bite-sized pcs\\n4. 1/4 c. French dressing or possibly 2 tbsp. salad dressing\\n### Directions: \\n1. Mix all ingredients together; toss.\\n2. Add in French dressing; mix well.\\n3. Yields 4 servings.']\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:52.719026Z",
     "start_time": "2026-02-18T00:22:52.711091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class Grade(BaseModel):\n",
    "    title: str = Field(description=\"Title of the document being scored.\")\n",
    "    analysis: str = Field(description=\"A brief sentence explaining the relevance score given.\")\n",
    "    score: int = Field(description=\"Relevance score ranging from 0 to 5, with 0 being completely irrelevant and 5 being highly relevant.\")\n",
    "\n",
    "class GradeList(BaseModel):\n",
    "    scores: List[Grade] = Field(description=\"List of relevance scores with analysis.\")"
   ],
   "id": "845053c9d03bb3e7",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:22:54.382932Z",
     "start_time": "2026-02-18T00:22:54.375093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "grader_prompt = \"\"\"\n",
    "You are a quality control agent. \n",
    "Your goal is to assess the relevance of the retrieved documents to a user question.\n",
    "Check each document in the list and return a integer score ranging between 0-5 with 0 being completely irrelevant and 5 being highly relevant for each of the document.\n",
    "\n",
    "## Grading criteria\n",
    "\n",
    "5 (Perfect): Matches specific name (e.g., \"Mom's\", \"Vicky's\", \"Gordon Ramsay's\" etc), all ingredients, all dietary constraints and flavour profiles.\n",
    "\n",
    "4 (Strong): Matches the dish type and all dietary constraints, but is a generic or different \"version\" of the specific recipe in the user's question.\n",
    "\n",
    "3 (Partial): Matches the dish type, meets most of the dietary needs or flavour profiles.\n",
    "\n",
    "0-2 (Irrelevant): Wrong dish type or fundamentally violates user's dietary constraints or flavour profiles.\n",
    "\n",
    "Return a JSON list containing one entry per document in the exact order of the documents provided. \n",
    "Return JSON in the exact format provided:\n",
    "{{\n",
    "  \"scores\": [\n",
    "    {{\n",
    "      \"title\":  \"Title of the document being scored.\"\n",
    "      \"analysis\": \"A brief sentence explaining the score given.\",\n",
    "      \"score\": Relevance score ranging from 0 to 5, with 0 being completely irrelevant and 5 being highly relevant\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "## Question: {question}\n",
    "## Documents: {documents}\n",
    "\"\"\"\n",
    "\n",
    "grader_prmpt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a strict grading API that ONLY outputs JSON.\"\n",
    "               \" Do not include any preamble, introduction, or explanation outside of the JSON structure.\"),\n",
    "    (\"human\", grader_prompt)\n",
    "])\n",
    "grader_llm = chat_ollama.with_structured_output(GradeList)\n",
    "grader_chain = grader_prmpt_template | grader_llm"
   ],
   "id": "33bd133dc160cea2",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:24:30.297092Z",
     "start_time": "2026-02-18T00:22:58.309278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grader_output = grader_chain.invoke({\"question\":question, \"documents\":re_ranked_docs})\n",
    "grader_output"
   ],
   "id": "52cf023491c43417",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeList(scores=[Grade(title='Huani', analysis=\"Directly addresses boiling eggs as part of the recipe, though it's a specific dish rather than just instructions for boiling eggs.\", score=4), Grade(title='Boiled Custard', analysis='Involves eggs but is a custard recipe, not about boiling eggs as the main focus. Violates the simple boiling instruction request.', score=1), Grade(title='Boiled Egg Salad Recipe', analysis='Uses boiled eggs but is a salad recipe, not focused on the boiling process itself. Partially relevant but not directly answering the question.', score=3)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:30:00.543701Z",
     "start_time": "2026-02-18T00:30:00.533005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ReformulatedQuery(BaseModel):\n",
    "    reasoning: str = Field(description=\"Why the original query failed and what is being changed.\")\n",
    "    relaxed_filters: dict = Field(description=\"The new metadata filters (e.g., removing 'is_quick').\")\n",
    "    new_content_query: str = Field(description=\"The new search string.\")\n",
    "\n",
    "\n",
    "\n",
    "# System Prompt for the Rewriter\n",
    "query_rewriter_prompt = \"\"\"You are a Query Optimizer. \n",
    "The previous search returned results that did not match the user's question.\n",
    "Analyze the constraints: {filters} for the query: {question}.\n",
    "\n",
    "Your goal:\n",
    "1. Identify the most restrictive constraint.\n",
    "2. Relax that constraint (e.g., if 'is_quick' was 1, set it to None).\n",
    "3. Keep dietary constraints (Vegan, Gluten free, Nut-free, Diary-free) as they are mandatory safety rules.\n",
    "4. Provide a new set of filters that is slightly broader.\n",
    "5. Do not add any new filters.\n",
    "\"\"\"\n",
    " \n",
    "query_rewriter_prompt_template = ChatPromptTemplate.from_template(query_rewriter_prompt)  \n",
    "rewriter_llm = chat_groq.with_structured_output(ReformulatedQuery)\n",
    "rewriter_chain = query_rewriter_prompt_template | rewriter_llm"
   ],
   "id": "ccb9473cd19472b0",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T00:30:03.698596Z",
     "start_time": "2026-02-18T00:30:02.834626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rewriter_output = rewriter_chain.invoke({\"question\": question, \"filters\": meta_data_filters})\n",
    "rewriter_output"
   ],
   "id": "8c2229686f2bba26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformulatedQuery(reasoning=\"The 'is_quick' constraint was overly restrictive for this query, so it has been relaxed.\", relaxed_filters={'is_no_oven': 1}, new_content_query='How to boil an egg?')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T04:43:45.030207Z",
     "start_time": "2026-02-14T04:43:45.018519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"\n",
    "<system-role>\n",
    "    You are a culinary master expert at answering questions.\n",
    "    Your goal is to provide clear, natural and helpful answers for a question based on the recipes provided.\n",
    " <system-role>\n",
    " </rules>   \n",
    "    1. DATA INTEGRITY: \n",
    "      - Answer using only the given context.\n",
    "      - Do not make assumptions based on titles. \n",
    "      - Use the provided ingredients and directions only. \n",
    "    2. STRICT DIETARY ALIGNMENT: \n",
    "        - Only include recipes that fully match the user's dietary requests. \n",
    "        - If a recipe in the context does not match the user constraints, EXCLUDE it.\n",
    "    3.MANDATORY STRUCTURE: For every matching recipe, you MUST provide:\n",
    "       - Recipe Name\n",
    "       - [DIETARY NOTE]: Explicitly state if it matches all user constraints or if there is a warning.\n",
    "         Suggest alternatives where possible.\n",
    "       - Prep/Cook Time (if available)\n",
    "       - Ingredients (bulleted)\n",
    "       - [TYPO NOTE]: If an ingredient amount seems like a typo (e.g., 12 tsp pepper), add: \"NOTE: Context says 12, likely 1/2.\"\n",
    "       - Step-by-step Directions (numbered)\n",
    "    4. Do not ask any follow-up questions.\n",
    "    5. Provide a direct answer in a professional tone.\n",
    "    6. Do not include any pre amble or post amble.\n",
    " </rules>\n",
    " <recipes>\n",
    "    {context}\n",
    " </recipes\n",
    " <question>\n",
    "    {question}\n",
    " </question>\n",
    "    \"\"\"\n",
    "rag_prmpt = ChatPromptTemplate.from_template(template)\n",
    "rag_chain = rag_prmpt | chat_ollama | StrOutputParser()"
   ],
   "id": "2b41a5b3491086c7",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T04:47:09.200721Z",
     "start_time": "2026-02-14T04:47:07.740428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(re_ranked_docs) > 5:\n",
    "    limited_docs = re_ranked_docs[0:5]\n",
    "else:\n",
    "    limited_docs = re_ranked_docs\n",
    "rag_response = rag_chain.invoke({\"context\": limited_docs, \"question\": question})\n",
    "print(rag_response)"
   ],
   "id": "90ef46948bb51cdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not see any recipe titled \"Mom's Meat Loaf\" in the provided context. The only recipe available is for \"Old Fashioned Meat Loaf\" which uses 2 eggs.\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T22:26:24.394665Z",
     "start_time": "2026-02-13T22:26:24.391057Z"
    }
   },
   "cell_type": "code",
   "source": "print(rag_response)",
   "id": "9d89f8db56ceb58f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided recipes, here are two no-cook salad options featuring citrus and beets:\n",
      "\n",
      "1. Spinach, Beet, And Egg Salad\n",
      "Ingredients:\n",
      "- 2 medium beets (precooked)\n",
      "- 2 hard-boiled eggs\n",
      "- 1 carrot, shredded\n",
      "- 2 cups spinach, washed and chopped\n",
      "- 1 cup lettuce\n",
      "- 12 almonds\n",
      "- Salad dressing of choice\n",
      "\n",
      "Directions:\n",
      "1. Use precooked beets - peel and chop them\n",
      "2. Hard boil eggs, peel and slice\n",
      "3. Mix all vegetables in a large bowl\n",
      "4. Add beets and eggs, mix together\n",
      "5. Top with almonds and dressing\n",
      "\n",
      "2. Mixed Baby Greens with Oranges, Grapefruit and Avocado\n",
      "(Note: While this doesn't contain beets, it's a no-cook citrus salad that could be adapted by adding precooked beets)\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb mixed baby greens\n",
      "- 2 oranges, peeled and sliced\n",
      "- 1 large grapefruit, peeled and sliced\n",
      "- 1 large avocado, peeled and sliced\n",
      "- 2 tbsp olive oil\n",
      "- 2 tbsp fruited balsamic vinegar\n",
      "- Kosher salt\n",
      "- Fresh ground pepper\n",
      "\n",
      "Directions:\n",
      "1. Combine lettuce with citrus and avocado\n",
      "2. Add olive oil, vinegar, salt and pepper\n",
      "3. Toss lightly\n",
      "\n",
      "To make a no-cook beet and citrus salad, you could combine elements from both recipes by adding precooked beets to the Mixed Baby Greens with Oranges, Grapefruit and Avocado salad.\n"
     ]
    }
   ],
   "execution_count": 146
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
